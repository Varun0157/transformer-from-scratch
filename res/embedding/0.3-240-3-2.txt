Hyperparameters:
- learning rate:  0.0005
- num layers:     3
- num heads:      2
- embedding dim:  240
- dropout:        0.3

Details:
- device:        cuda
- batch size:    4
- criterion:     <class 'torch.nn.modules.loss.CrossEntropyLoss'>
- optimizer:     <class 'torch.optim.adam.Adam'>
- eng vocab len: 21178
- fr vocab len:  30437

epoch 0 -> train loss: 132.0755, eval loss: 135.2587	time: 322.23s
	model saved
epoch 1 -> train loss: 123.6224, eval loss: 139.9920	time: 296.95s
epoch 2 -> train loss: 119.0127, eval loss: 137.5010	time: 295.43s
epoch 3 -> train loss: 115.5072, eval loss: 131.9575	time: 290.88s
	model saved
epoch 4 -> train loss: 113.2669, eval loss: 134.4874	time: 293.98s
epoch 5 -> train loss: 111.7508, eval loss: 132.3461	time: 334.12s
epoch 6 -> train loss: 110.5649, eval loss: 131.3790	time: 312.39s
	model saved
epoch 7 -> train loss: 109.6408, eval loss: 130.9946	time: 265.29s
	model saved
epoch 8 -> train loss: 108.8054, eval loss: 131.7357	time: 324.68s
epoch 9 -> train loss: 108.0852, eval loss: 130.0423	time: 307.46s
	model saved

training complete.
